{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Dataset",
      "provenance": [],
      "authorship_tag": "ABX9TyNGVp44HCXlnGTkUzO/+OSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeep5500/kaggle_attempts/blob/main/Titanic_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etpgkyL3ogcp"
      },
      "source": [
        "**0.77751** accuracy with **XGBoost** model on Titanic dataset.\r\n",
        "(Random forests attempt included as well)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76N8QrgJluEi",
        "outputId": "543ce00a-db5d-47ec-a618-fb64c98bb0f7"
      },
      "source": [
        "## Kaggle conf\r\n",
        "!pip install kaggle\r\n",
        "!mkdir .kaggle\r\n",
        "import json\r\n",
        "token = {\"username\":\"sandeepkumar00\",\"key\":\"006083ef889a4c38471af6b2ce139874\"}\r\n",
        "with open('.kaggle/kaggle.json', 'w') as file:\r\n",
        "    json.dump(token, file)  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAp33BB6mJjX",
        "outputId": "dcf5606c-b4d2-4c37-b9bb-c11659db296d"
      },
      "source": [
        "!cp .kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!kaggle config set -n path -v .\r\n",
        "!chmod 600 .kaggle/kaggle.json\r\n",
        "!kaggle datasets list\r\n",
        "!kaggle competitions download -c titanic "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: .\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                            title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "arashnic/hr-analytics-job-change-of-data-scientists            HR Analytics: Job Change of Data Scientists        295KB  2020-12-07 00:25:10            596  \n",
            "babyoda/access-to-computers-from-home-oecd                     Access to Computers From Home OECD                   3KB  2020-12-04 10:50:09             13  \n",
            "shashwatwork/impact-of-covid19-pandemic-on-the-global-economy  Impact of Covid-19 Pandemic on the Global Economy    1MB  2020-11-29 14:16:30            141  \n",
            "emmanuelleai/world-marathons-majors                            World Marathons Majors                               7KB  2020-12-06 19:24:28             21  \n",
            "mrmorj/dataset-of-songs-in-spotify                             Dataset of songs in Spotify                          3MB  2020-12-06 09:46:55             48  \n",
            "boramalper/scihub-papers                                       Sci-Hub Papers                                       6GB  2020-12-06 04:10:54              2  \n",
            "juicobowley/drake-lyrics                                       Drake Lyrics                                       764KB  2020-11-27 01:00:52             18  \n",
            "kavisekar/oecd-unemployment-rate-2020                          OECD Unemployment rate (2020)                        3KB  2020-12-07 15:37:38             27  \n",
            "kingabzpro/datascience-survey-on-kaggle                        data science survey on Kaggle                      129KB  2020-11-24 19:04:19              9  \n",
            "sakshigoyal7/credit-card-customers                             Credit Card customers                              379KB  2020-11-19 07:38:44          11750  \n",
            "szymonjanowski/internet-articles-data-with-users-engagement    Internet news data with readers engagement           3MB  2020-11-21 17:09:57           3407  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019          Amazon Top 50 Bestselling Books 2009 - 2019         15KB  2020-10-13 09:39:21          10357  \n",
            "alexgude/california-traffic-collision-data-from-switrs         California Traffic Collision Data from SWITRS        1GB  2020-11-22 16:51:55           2086  \n",
            "babyoda/women-entrepreneurship-and-labor-force                 Women Entrepreneurship and Labor Force               1KB  2020-11-21 08:38:51           5010  \n",
            "shivamb/netflix-shows                                          Netflix Movies and TV Shows                        971KB  2020-01-20 07:33:56          76419  \n",
            "yamaerenay/spotify-dataset-19212020-160k-tracks                Spotify Dataset 1921-2020, 160k+ Tracks             16MB  2020-11-25 21:14:12          12895  \n",
            "patrickb1912/ipl-complete-dataset-20082020                     IPL Complete Dataset (2008-2020)                     1MB  2020-11-23 06:53:37           2624  \n",
            "manchunhui/us-election-2020-tweets                             US Election 2020 Tweets                            353MB  2020-11-09 18:51:59           5371  \n",
            "imoore/2020-us-general-election-turnout-rates                  2020 US General Election Turnout rates               4KB  2020-11-26 00:21:15           3571  \n",
            "google/tinyquickdraw                                           QuickDraw Sketches                                  11GB  2018-04-18 19:38:04           2649  \n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4bg7hF0mOSY"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "train = pd.read_csv('/content/competitions/titanic/train.csv', header=0)\r\n",
        "test = pd.read_csv('/content/competitions/titanic/test.csv', header=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZQ8aXH8mfLV",
        "outputId": "c3320e6f-d3a4-406b-c80c-558cad39a017"
      },
      "source": [
        "print(train)\r\n",
        "print(test)\r\n",
        "final_train_y = train[\"Survived\"]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     PassengerId  Survived  Pclass  ... Cabin Embarked  Married Woman\n",
            "0              1         0       3  ...   NaN        S              0\n",
            "1              2         1       1  ...   C85        C              1\n",
            "2              3         1       3  ...   NaN        S              0\n",
            "3              4         1       1  ...  C123        S              1\n",
            "4              5         0       3  ...   NaN        S              0\n",
            "..           ...       ...     ...  ...   ...      ...            ...\n",
            "886          887         0       2  ...   NaN        S              0\n",
            "887          888         1       1  ...   B42        S              0\n",
            "888          889         0       3  ...   NaN        S              1\n",
            "889          890         1       1  ...  C148        C              0\n",
            "890          891         0       3  ...   NaN        Q              0\n",
            "\n",
            "[891 rows x 13 columns]\n",
            "     PassengerId  Pclass  ... Embarked Married Woman\n",
            "0            892       3  ...        Q             0\n",
            "1            893       3  ...        S             1\n",
            "2            894       2  ...        Q             0\n",
            "3            895       3  ...        S             0\n",
            "4            896       3  ...        S             1\n",
            "..           ...     ...  ...      ...           ...\n",
            "413         1305       3  ...        S             0\n",
            "414         1306       1  ...        C             0\n",
            "415         1307       3  ...        S             0\n",
            "416         1308       3  ...        S             0\n",
            "417         1309       3  ...        C             0\n",
            "\n",
            "[418 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiN8yd7A7qIX"
      },
      "source": [
        "train[\"Married Woman\"] = np.where(train[\"Name\"].str.len() >30, 1, 0)\r\n",
        "test[\"Married Woman\"] = np.where(test[\"Name\"].str.len() >30, 1, 0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHWNnlLCnehT",
        "outputId": "a0a15f7f-084a-4bde-bac3-d22089559934"
      },
      "source": [
        "cols_of_interest1 = [\"Pclass\",\"Sex\", \"Age\", \"Embarked\",\"Fare\",\"Married Woman\"]\r\n",
        "cols_of_interest2 = [\"Pclass\",\"Sex\",\"Age\",\"Embarked\",\"Fare\",\"Married Woman\"]\r\n",
        "cor_train = train.loc[:,cols_of_interest1]\r\n",
        "print(cor_train)\r\n",
        "cor_test = test.loc[:,cols_of_interest2]\r\n",
        "print(cor_test)\r\n",
        "\r\n",
        "total = cor_train.append(cor_test)\r\n",
        "print(total)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Pclass     Sex   Age Embarked     Fare  Married Woman\n",
            "0         3    male  22.0        S   7.2500              0\n",
            "1         1  female  38.0        C  71.2833              1\n",
            "2         3  female  26.0        S   7.9250              0\n",
            "3         1  female  35.0        S  53.1000              1\n",
            "4         3    male  35.0        S   8.0500              0\n",
            "..      ...     ...   ...      ...      ...            ...\n",
            "886       2    male  27.0        S  13.0000              0\n",
            "887       1  female  19.0        S  30.0000              0\n",
            "888       3  female   NaN        S  23.4500              1\n",
            "889       1    male  26.0        C  30.0000              0\n",
            "890       3    male  32.0        Q   7.7500              0\n",
            "\n",
            "[891 rows x 6 columns]\n",
            "     Pclass     Sex   Age Embarked      Fare  Married Woman\n",
            "0         3    male  34.5        Q    7.8292              0\n",
            "1         3  female  47.0        S    7.0000              1\n",
            "2         2    male  62.0        Q    9.6875              0\n",
            "3         3    male  27.0        S    8.6625              0\n",
            "4         3  female  22.0        S   12.2875              1\n",
            "..      ...     ...   ...      ...       ...            ...\n",
            "413       3    male   NaN        S    8.0500              0\n",
            "414       1  female  39.0        C  108.9000              0\n",
            "415       3    male  38.5        S    7.2500              0\n",
            "416       3    male   NaN        S    8.0500              0\n",
            "417       3    male   NaN        C   22.3583              0\n",
            "\n",
            "[418 rows x 6 columns]\n",
            "     Pclass     Sex   Age Embarked      Fare  Married Woman\n",
            "0         3    male  22.0        S    7.2500              0\n",
            "1         1  female  38.0        C   71.2833              1\n",
            "2         3  female  26.0        S    7.9250              0\n",
            "3         1  female  35.0        S   53.1000              1\n",
            "4         3    male  35.0        S    8.0500              0\n",
            "..      ...     ...   ...      ...       ...            ...\n",
            "413       3    male   NaN        S    8.0500              0\n",
            "414       1  female  39.0        C  108.9000              0\n",
            "415       3    male  38.5        S    7.2500              0\n",
            "416       3    male   NaN        S    8.0500              0\n",
            "417       3    male   NaN        C   22.3583              0\n",
            "\n",
            "[1309 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDEDxzpAgEZT",
        "outputId": "78bbb704-33e7-4b52-c7a4-9e165ed78202"
      },
      "source": [
        "total.isnull().sum()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass             0\n",
              "Sex                0\n",
              "Age              263\n",
              "Embarked           2\n",
              "Fare               1\n",
              "Married Woman      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SQq0VSJYIfP"
      },
      "source": [
        "total_imp = total\r\n",
        "\r\n",
        "avg_age = total['Age'].mean()\r\n",
        "total_imp[\"Age\"].fillna(avg_age,inplace=True)\r\n",
        "total_imp[\"Fare\"].fillna(total['Fare'].mean(),inplace=True)\r\n",
        "\r\n",
        "mode_cols = [\"Embarked\"]\r\n",
        "total_imp[mode_cols]=total_imp[mode_cols].fillna(total_imp.mode().iloc[0])\r\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPfmAoT6clmJ",
        "outputId": "a7ce8e1c-a905-4727-92a5-9dd9275d570e"
      },
      "source": [
        "total.isnull().sum()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass           0\n",
              "Sex              0\n",
              "Age              0\n",
              "Embarked         0\n",
              "Fare             0\n",
              "Married Woman    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tatup0y_r0JM",
        "outputId": "6a606411-9b26-4e10-daf6-e9506d91f700"
      },
      "source": [
        "onehot_cols = [\"Pclass\",\"Sex\", \"Embarked\"]\r\n",
        "print(onehot_cols)\r\n",
        "total_oh_df = pd.get_dummies(total_imp, columns=onehot_cols)\r\n",
        "print(total_oh_df)\r\n",
        "print(total_oh_df.columns)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Pclass', 'Sex', 'Embarked']\n",
            "           Age      Fare  Married Woman  ...  Embarked_C  Embarked_Q  Embarked_S\n",
            "0    22.000000    7.2500              0  ...           0           0           1\n",
            "1    38.000000   71.2833              1  ...           1           0           0\n",
            "2    26.000000    7.9250              0  ...           0           0           1\n",
            "3    35.000000   53.1000              1  ...           0           0           1\n",
            "4    35.000000    8.0500              0  ...           0           0           1\n",
            "..         ...       ...            ...  ...         ...         ...         ...\n",
            "413  29.881138    8.0500              0  ...           0           0           1\n",
            "414  39.000000  108.9000              0  ...           1           0           0\n",
            "415  38.500000    7.2500              0  ...           0           0           1\n",
            "416  29.881138    8.0500              0  ...           0           0           1\n",
            "417  29.881138   22.3583              0  ...           1           0           0\n",
            "\n",
            "[1309 rows x 11 columns]\n",
            "Index(['Age', 'Fare', 'Married Woman', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
            "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLalS8GCs7KE",
        "outputId": "1aa58d77-df6c-418a-a521-19fa0ec21d88"
      },
      "source": [
        "final_train_x = total_oh_df.iloc[:891]\r\n",
        "final_test_x = total_oh_df.iloc[891:]\r\n",
        "print(final_train_x)\r\n",
        "print(final_test_x)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Age     Fare  Married Woman  ...  Embarked_C  Embarked_Q  Embarked_S\n",
            "0    22.000000   7.2500              0  ...           0           0           1\n",
            "1    38.000000  71.2833              1  ...           1           0           0\n",
            "2    26.000000   7.9250              0  ...           0           0           1\n",
            "3    35.000000  53.1000              1  ...           0           0           1\n",
            "4    35.000000   8.0500              0  ...           0           0           1\n",
            "..         ...      ...            ...  ...         ...         ...         ...\n",
            "886  27.000000  13.0000              0  ...           0           0           1\n",
            "887  19.000000  30.0000              0  ...           0           0           1\n",
            "888  29.881138  23.4500              1  ...           0           0           1\n",
            "889  26.000000  30.0000              0  ...           1           0           0\n",
            "890  32.000000   7.7500              0  ...           0           1           0\n",
            "\n",
            "[891 rows x 11 columns]\n",
            "           Age      Fare  Married Woman  ...  Embarked_C  Embarked_Q  Embarked_S\n",
            "0    34.500000    7.8292              0  ...           0           1           0\n",
            "1    47.000000    7.0000              1  ...           0           0           1\n",
            "2    62.000000    9.6875              0  ...           0           1           0\n",
            "3    27.000000    8.6625              0  ...           0           0           1\n",
            "4    22.000000   12.2875              1  ...           0           0           1\n",
            "..         ...       ...            ...  ...         ...         ...         ...\n",
            "413  29.881138    8.0500              0  ...           0           0           1\n",
            "414  39.000000  108.9000              0  ...           1           0           0\n",
            "415  38.500000    7.2500              0  ...           0           0           1\n",
            "416  29.881138    8.0500              0  ...           0           0           1\n",
            "417  29.881138   22.3583              0  ...           1           0           0\n",
            "\n",
            "[418 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwaj4XrotvF0"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj343JAImjYb"
      },
      "source": [
        "gbm = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, learning_rate=0.05, max_depth = 9, n_estimators= 500, reg_alpha= 0.5, reg_lambda= 0.5,colsample_bytree=0.4)\r\n",
        "\r\n",
        "gbm.fit(final_train_x, final_train_y)\r\n",
        "predictions = gbm.predict(final_test_x)\r\n",
        "\r\n",
        "# Dump predictions into csv file\r\n",
        "submission = pd.DataFrame({ 'PassengerId': test[\"PassengerId\"],\r\n",
        "                            'Survived': predictions })\r\n",
        "submission.to_csv(\"submission.csv\", index=False)\r\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fLzJHjt6ZGH"
      },
      "source": [
        "**Submission Comparer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzsj4Wwz6Yc2",
        "outputId": "55a1f0db-5571-4989-ca54-7b91d0b48394"
      },
      "source": [
        "sub1 = pd.read_csv('/content/submission4.csv', header=0)\r\n",
        "sub2 = pd.read_csv('/content/submission.csv', header=0)\r\n",
        "n_diff = 0\r\n",
        "for ind in sub1.index: \r\n",
        "     if sub1['Survived'][ind] != sub2['Survived'][ind]:\r\n",
        "         n_diff+=1\r\n",
        "         print(sub1['PassengerId'][ind])\r\n",
        "print(\"Total Diff: \",n_diff)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898\n",
            "910\n",
            "926\n",
            "927\n",
            "946\n",
            "964\n",
            "965\n",
            "982\n",
            "986\n",
            "1010\n",
            "1028\n",
            "1049\n",
            "1051\n",
            "1063\n",
            "1098\n",
            "1141\n",
            "1198\n",
            "1205\n",
            "1210\n",
            "1261\n",
            "1271\n",
            "1274\n",
            "1309\n",
            "Total Diff:  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeEGaA0q7Lk",
        "outputId": "a52fa68b-1c6c-40c5-9897-78c2ae05d2fd"
      },
      "source": [
        "import sklearn\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "gbm2 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, learning_rate = 0.05)\r\n",
        "params = {\r\n",
        "        \"n_estimators\": [500, 700, 1000],\r\n",
        "        \"max_depth\": [ 7, 9, 11],\r\n",
        "        \"reg_alpha\": [0.3, 0.5, 0.7],\r\n",
        "        \"reg_lambda\": [0.3, 0.5, 0.8],\r\n",
        "        \"colsample_bytree\": [0.4, 0.7, 1]\r\n",
        "    }\r\n",
        "grid = GridSearchCV(gbm2, params, refit = True, verbose = 1,cv =4, n_jobs=-1) \r\n",
        "   \r\n",
        "# fitting the model for grid search \r\n",
        "grid.fit(final_train_x, final_train_y) \r\n",
        " \r\n",
        "# print best parameter after tuning \r\n",
        "print(grid.best_params_) \r\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 243 candidates, totalling 972 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   58.2s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'colsample_bytree': 0.4, 'max_depth': 9, 'n_estimators': 500, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhhHyS0c2S_Q",
        "outputId": "91cd8e61-ff88-4082-87e0-2ef545f09e63"
      },
      "source": [
        "print(grid.best_score_)\r\n",
        "grid_predictions = grid.predict(final_test_x) \r\n",
        "# Dump predictions into csv file\r\n",
        "submission = pd.DataFrame({ 'PassengerId': test[\"PassengerId\"],\r\n",
        "                            'Survived': grid_predictions })\r\n",
        "submission.to_csv(\"submission2.csv\", index=False)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8361410738092352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x0ZhvnNpfFi"
      },
      "source": [
        "**Random Forests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBOqGTKA5Dsx"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "regmodel = RandomForestClassifier(n_estimators=20, random_state=0)\r\n",
        "regmodel.fit(final_train_x, final_train_y)\r\n",
        "regpredictions = regmodel.predict(final_test_x)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUOPiofVWJKn"
      },
      "source": [
        "# Dump predictions into csv file\r\n",
        "submission = pd.DataFrame({ 'PassengerId': test[\"PassengerId\"],\r\n",
        "                            'Survived': regpredictions })\r\n",
        "submission.to_csv(\"submission3.csv\", index=False)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GF2anVHlF6L",
        "outputId": "9258fb87-a9fd-4fb4-a683-f4e4a65fc971"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "rf = RandomForestClassifier( random_state=0)\r\n",
        "random_grid = {\r\n",
        "'bootstrap': [True, False],\r\n",
        " 'max_depth': [10, 40, 70, 100, None],\r\n",
        " 'max_features': ['auto', 'sqrt'],\r\n",
        " 'min_samples_leaf': [1, 2, 4],\r\n",
        " 'min_samples_split': [2, 5, 10],\r\n",
        " 'n_estimators': [200, 600, 800, 1400]}\r\n",
        "\r\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\r\n",
        "# Fit the random search model\r\n",
        "rf_random.fit(final_train_x, final_train_y)\r\n",
        "regrandpredictions = rf_random.predict(final_test_x)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   28.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.5min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIu3IKxdl3fD",
        "outputId": "668b1314-4988-475a-b941-aa1610b915aa"
      },
      "source": [
        "print(rf_random.best_score_)\r\n",
        "print(rf_random.best_params_)\r\n",
        "submission = pd.DataFrame({ 'PassengerId': test[\"PassengerId\"],\r\n",
        "                            'Survived': regrandpredictions })\r\n",
        "submission.to_csv(\"submission4.csv\", index=False)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8271604938271605\n",
            "{'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSxDtzKanz09"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}